#!/usr/bin/env python3
"""
Enhanced Question Bank Generator for Digital and Data Communication (4343201)
Comprehensive bilingual question extraction and mapping system for DDC
"""

import json
import re
import os
from pathlib import Path
from typing import Dict, List, Tuple, Set, Optional
from collections import defaultdict, Counter
import unicodedata
from dataclasses import dataclass, asdict
import hashlib

@dataclass
class Question:
    """Question data structure"""
    id: str
    text: str
    language: str  # 'english' or 'gujarati'
    marks: int
    source_file: str
    exam_year: str
    exam_season: str
    unit: Optional[str] = None
    topics: List[str] = None
    confidence: float = 0.0

class EnhancedDDCQuestionBankGenerator:
    """Enhanced question bank generator for Digital and Data Communication"""
    
    def __init__(self, base_path: str):
        self.base_path = Path(base_path)
        self.syllabus_data = {}
        self.questions = []
        
        # Enhanced bilingual keyword mappings for Digital and Data Communication
        self.unit_keywords = {
            "Unit-I": {
                "english": [
                    # Digital communication basics
                    "digital communication", "system", "block diagram", "source", "channel", 
                    "transmitter", "receiver", "repeater", "elements",
                    
                    # Channel characteristics
                    "bit rate", "baud rate", "bandwidth", "repeater distance", "channel characteristics",
                    "communication channel", "telephone channel", "coaxial cable", "optical fiber",
                    "wireless channel", "satellite channel",
                    
                    # Communication types and modes
                    "broadcasting", "point to point", "simplex", "duplex", "communication modes",
                    "basic modes", "broad casting", "point to point communication",
                    
                    # Multiplexing
                    "multiplexing", "TDM", "FDM", "CDM", "time division", "frequency division",
                    "code division", "need of multiplexing", "methods of multiplexing",
                    
                    # System limitations and advantages
                    "fundamental limitation", "digital system", "noise", "equipment",
                    "advantages", "disadvantages", "digital communication system"
                ],
                "gujarati": [
                    # àª¡àª¿àªœàª¿àªŸàª² àª•à«‹àª®à«àª¯à«àª¨àª¿àª•à«‡àª¶àª¨ àª®à«‚àª³àª­à«‚àª¤à«‹
                    "àª¡àª¿àªœàª¿àªŸàª² àª•à«‹àª®à«àª¯à«àª¨àª¿àª•à«‡àª¶àª¨", "àª¸àª¿àª¸à«àªŸàª®", "àª¬à«àª²à«‹àª• àª¡àª¾àª¯àª¾àª—à«àª°àª¾àª®", "àª¸à«‹àª°à«àª¸", "àªšà«‡àª¨àª²",
                    "àªŸà«àª°àª¾àª¨à«àª¸àª®àª¿àªŸàª°", "àª°àª¿àª¸à«€àªµàª°", "àª°à«€àªªà«€àªŸàª°", "àª¤àª¤à«àªµà«‹", "àª˜àªŸàª•à«‹",
                    
                    # àªšà«‡àª¨àª² àª²àª¾àª•à«àª·àª£àª¿àª•àª¤àª¾àª“
                    "àª¬àª¿àªŸ àª°à«‡àªŸ", "àª¬àª¾àª‰àª¡ àª°à«‡àªŸ", "àª¬à«‡àª¨à«àª¡àªµàª¿àª¡à«àª¥", "àª°à«€àªªà«€àªŸàª° àª…àª‚àª¤àª°", "àªšà«‡àª¨àª² àª²àª¾àª•à«àª·àª£àª¿àª•àª¤àª¾àª“",
                    "àª•à«‹àª®à«àª¯à«àª¨àª¿àª•à«‡àª¶àª¨ àªšà«‡àª¨àª²", "àªŸà«‡àª²àª¿àª«à«‹àª¨ àªšà«‡àª¨àª²", "àª•à«‹àªàª•à«àª¸àª¿àª¯àª² àª•à«‡àª¬àª²", "àª“àªªà«àªŸàª¿àª•àª² àª«àª¾àª‡àª¬àª°",
                    "àªµàª¾àª¯àª°àª²à«‡àª¸ àªšà«‡àª¨àª²", "àª¸à«‡àªŸà«‡àª²àª¾àª‡àªŸ àªšà«‡àª¨àª²",
                    
                    # àª•à«‹àª®à«àª¯à«àª¨àª¿àª•à«‡àª¶àª¨ àªªà«àª°àª•àª¾àª°à«‹ àª…àª¨à«‡ àª®à«‹àª¡à«àª¸
                    "àª¬à«àª°à«‹àª¡àª•àª¾àª¸à«àªŸàª¿àª‚àª—", "àªªà«‹àªˆàª¨à«àªŸ àªŸà« àªªà«‹àªˆàª¨à«àªŸ", "àª¸àª¿àª®à«àªªà«àª²à«‡àª•à«àª¸", "àª¡à«àªªà«àª²à«‡àª•à«àª¸", "àª•à«‹àª®à«àª¯à«àª¨àª¿àª•à«‡àª¶àª¨ àª®à«‹àª¡à«àª¸",
                    "àª®à«‚àª³àª­à«‚àª¤ àª®à«‹àª¡à«àª¸", "àª¬à«àª°à«‹àª¡ àª•àª¾àª¸à«àªŸàª¿àª‚àª—", "àªªà«‹àªˆàª¨à«àªŸ àªŸà« àªªà«‹àªˆàª¨à«àªŸ àª•àª®à«àª¯à«àª¨àª¿àª•à«‡àª¶àª¨",
                    
                    # àª®àª²à«àªŸàª¿àªªà«àª²à«‡àª•à«àª¸àª¿àª‚àª—
                    "àª®àª²à«àªŸàª¿àªªà«àª²à«‡àª•à«àª¸àª¿àª‚àª—", "TDM", "FDM", "CDM", "àªŸàª¾àª‡àª® àª¡àª¿àªµàª¿àªàª¨", "àª«à«àª°à«€àª•à«àªµàª¨à«àª¸à«€ àª¡àª¿àªµàª¿àªàª¨",
                    "àª•à«‹àª¡ àª¡àª¿àªµàª¿àªàª¨", "àª®àª²à«àªŸàª¿àªªà«àª²à«‡àª•à«àª¸àª¿àª‚àª—àª¨à«€ àªœàª°à«‚àª°", "àª®àª²à«àªŸàª¿àªªà«àª²à«‡àª•à«àª¸àª¿àª‚àª—àª¨à«€ àªªàª¦à«àª§àª¤àª¿àª“",
                    
                    # àª¸àª¿àª¸à«àªŸàª® àª®àª°à«àª¯àª¾àª¦àª¾àª“ àª…àª¨à«‡ àª«àª¾àª¯àª¦àª¾àª“
                    "àª®à«‚àª³àª­à«‚àª¤ àª®àª°à«àª¯àª¾àª¦àª¾", "àª¡àª¿àªœàª¿àªŸàª² àª¸àª¿àª¸à«àªŸàª®", "àª¨à«‹àª‡àª", "àª‰àªªàª•àª°àª£à«‹", "àª¸àª¾àª§àª¨à«‹",
                    "àª«àª¾àª¯àª¦àª¾", "àª—à«‡àª°àª«àª¾àª¯àª¦àª¾", "àª¡àª¿àªœàª¿àªŸàª² àª•à«‹àª®à«àª¯à«àª¨àª¿àª•à«‡àª¶àª¨ àª¸àª¿àª¸à«àªŸàª®"
                ]
            },
            
            "Unit-II": {
                "english": [
                    # Digital modulation techniques
                    "digital modulation", "modulation techniques", "shift keying", "ASK", "FSK", "PSK", "QPSK",
                    "amplitude shift keying", "frequency shift keying", "phase shift keying",
                    "quadrature phase shift keying", "binary phase shift keying", "BPSK",
                    
                    # Modulation characteristics
                    "generation", "detection", "reception", "bandwidth", "constellation diagram",
                    "waveforms", "modulator", "demodulator", "coherent", "non-coherent",
                    
                    # QAM and advanced modulation
                    "QAM", "quadrature amplitude modulation", "16-QAM", "principle",
                    "constellation", "advantages", "disadvantages", "comparison",
                    
                    # Modulation analysis
                    "compare", "salient features", "summarize", "explain generation",
                    "draw waveform", "block diagram", "working principle"
                ],
                "gujarati": [
                    # àª¡àª¿àªœàª¿àªŸàª² àª®à«‹àª¡à«àª¯à«àª²à«‡àª¶àª¨ àª¤àª•àª¨à«€àª•à«‹
                    "àª¡àª¿àªœàª¿àªŸàª² àª®à«‹àª¡à«àª¯à«àª²à«‡àª¶àª¨", "àª®à«‹àª¡à«àª¯à«àª²à«‡àª¶àª¨ àª¤àª•àª¨à«€àª•à«‹", "àª¶àª¿àª«à«àªŸ àª•à«€àª‡àª‚àª—", "ASK", "FSK", "PSK", "QPSK",
                    "àªàª®à«àªªà«àª²àª¿àªŸà«àª¯à«àª¡ àª¶àª¿àª«à«àªŸ àª•à«€àª‡àª‚àª—", "àª«à«àª°à«€àª•à«àªµàª¨à«àª¸à«€ àª¶àª¿àª«à«àªŸ àª•à«€àª‡àª‚àª—", "àª«à«‡àª àª¶àª¿àª«à«àªŸ àª•à«€àª‡àª‚àª—",
                    "àª•à«àªµàª¾àª¡àª°à«‡àªšàª° àª«à«‡àª àª¶àª¿àª«à«àªŸ àª•à«€àª‡àª‚àª—", "àª¬àª¾àª‡àª¨àª°à«€ àª«à«‡àª àª¶àª¿àª«à«àªŸ àª•à«€àª‡àª‚àª—", "BPSK",
                    
                    # àª®à«‹àª¡à«àª¯à«àª²à«‡àª¶àª¨ àª²àª¾àª•à«àª·àª£àª¿àª•àª¤àª¾àª“
                    "àªœàª¨àª°à«‡àª¶àª¨", "àª¡àª¿àªŸà«‡àª•à«àª¶àª¨", "àª°àª¿àª¸à«‡àªªà«àª¶àª¨", "àª¬à«‡àª¨à«àª¡àªµàª¿àª¡à«àª¥", "àª¨àª•à«àª·àª¤à«àª° àª†àª•à«ƒàª¤àª¿", "àª•à«‹àª¨à«àª¸à«àªŸà«‡àª²à«‡àª¶àª¨",
                    "àªµà«‡àªµàª«à«‹àª°à«àª®", "àª®à«‹àª¡à«àª¯à«àª²à«‡àªŸàª°", "àª¡àª¿àª®à«‹àª¡à«àª¯à«àª²à«‡àªŸàª°", "àª•à«‹àª¹à«‡àª°à«‡àª‚àªŸ", "àª¨à«‹àª¨-àª•à«‹àª¹à«‡àª°à«‡àª‚àªŸ",
                    
                    # QAM àª…àª¨à«‡ àª…àª¦à«àª¯àª¤àª¨ àª®à«‹àª¡à«àª¯à«àª²à«‡àª¶àª¨
                    "QAM", "àª•à«àªµàª¾àª¡àª°à«‡àªšàª° àªàª®à«àªªà«àª²àª¿àªŸà«àª¯à«àª¡ àª®à«‹àª¡à«àª¯à«àª²à«‡àª¶àª¨", "16-QAM", "àª¸àª¿àª¦à«àª§àª¾àª‚àª¤",
                    "àª¨àª•à«àª·àª¤à«àª° àª†àª•à«ƒàª¤àª¿", "àª«àª¾àª¯àª¦àª¾", "àª—à«‡àª°àª«àª¾àª¯àª¦àª¾", "àª¸àª°àª–àª¾àª®àª£à«€",
                    
                    # àª®à«‹àª¡à«àª¯à«àª²à«‡àª¶àª¨ àªµàª¿àª¶à«àª²à«‡àª·àª£
                    "àª¸àª°àª–àª¾àª®àª£à«€", "àª®à«àª–à«àª¯ àª²àª•à«àª·àª£à«‹", "àª¸àª¾àª°àª¾àª‚àª¶", "àªœàª¨àª°à«‡àª¶àª¨ àª¸àª®àªœàª¾àªµà«‹",
                    "àªµà«‡àªµàª«à«‹àª°à«àª® àª¦à«‹àª°à«‹", "àª¬à«àª²à«‹àª• àª¡àª¾àª¯àª¾àª—à«àª°àª¾àª®", "àª•àª¾àª°à«àª¯àª¸àª¿àª¦à«àª§àª¾àª‚àª¤"
                ]
            },
            
            "Unit-III": {
                "english": [
                    # Information theory basics
                    "information theory", "probability", "entropy", "information", "mutual information",
                    "significance of probability", "channel capacity", "SNR", "signal to noise ratio",
                    "shannon", "channel capacity formula",
                    
                    # Source coding
                    "source coding", "huffman code", "shannon fano code", "coding techniques",
                    "huffman coding", "shannon-fano", "variable length", "prefix code",
                    "compression", "lossless", "encoding", "decoding",
                    
                    # Channel coding and error control
                    "channel coding", "error detection", "error correction", "parity", "checksum",
                    "hamming code", "cyclic redundancy check", "CRC", "error causes", "error effect",
                    
                    # Line coding
                    "line coding", "line codes", "NRZ", "RZ", "manchester", "AMI",
                    "unipolar", "polar", "bipolar", "classification", "properties",
                    "selection", "comparison", "waveform"
                ],
                "gujarati": [
                    # àª®àª¾àª¹àª¿àª¤à«€ àª¸àª¿àª¦à«àª§àª¾àª‚àª¤ àª®à«‚àª³àª­à«‚àª¤à«‹
                    "àª®àª¾àª¹àª¿àª¤à«€ àª¸àª¿àª¦à«àª§àª¾àª‚àª¤", "àª¸àª‚àª­àª¾àªµàª¨àª¾", "àªàª¨à«àªŸà«àª°à«‹àªªà«€", "àª®àª¾àª¹àª¿àª¤à«€", "àªªàª°àª¸à«àªªàª° àª®àª¾àª¹àª¿àª¤à«€",
                    "àª¸àª‚àª­àª¾àªµàª¨àª¾àª¨à«àª‚ àª®àª¹àª¤à«àªµ", "àªšà«‡àª¨àª² àª•à«àª·àª®àª¤àª¾", "SNR", "àª¸àª¿àª—à«àª¨àª² àªŸà« àª¨à«‹àª‡àª àª°à«‡àª¶àª¿àª¯à«‹",
                    "àª¶à«‡àª¨à«‹àª¨", "àªšà«‡àª¨àª² àª•à«àª·àª®àª¤àª¾ àª«à«‹àª°à«àª®à«àª¯à«àª²àª¾",
                    
                    # àª¸à«‹àª°à«àª¸ àª•à«‹àª¡àª¿àª‚àª—
                    "àª¸à«‹àª°à«àª¸ àª•à«‹àª¡àª¿àª‚àª—", "àª¹àª«àª®à«‡àª¨ àª•à«‹àª¡", "àª¶à«‡àª¨à«‹àª¨ àª«àª¾àª¡à«‹ àª•à«‹àª¡", "àª•à«‹àª¡àª¿àª‚àª— àª¤àª•àª¨à«€àª•à«‹",
                    "àª¹àª«àª®à«‡àª¨ àª•à«‹àª¡àª¿àª‚àª—", "àª¶à«‡àª¨à«‹àª¨-àª«àª¾àª¡à«‹", "àªµà«‡àª°àª¿àªàª¬àª² àª²à«‡àª¨à«àª¥", "àªªà«àª°à«€àª«àª¿àª•à«àª¸ àª•à«‹àª¡",
                    "àª•àª®à«àªªà«àª°à«‡àª¶àª¨", "àª²à«‹àª¸àª²à«‡àª¸", "àªàª¨à«àª•à«‹àª¡àª¿àª‚àª—", "àª¡à«€àª•à«‹àª¡àª¿àª‚àª—",
                    
                    # àªšà«‡àª¨àª² àª•à«‹àª¡àª¿àª‚àª— àª…àª¨à«‡ àªàª°àª° àª•àª‚àªŸà«àª°à«‹àª²
                    "àªšà«‡àª¨àª² àª•à«‹àª¡àª¿àª‚àª—", "àªàª°àª° àª¡àª¿àªŸà«‡àª•à«àª¶àª¨", "àªàª°àª° àª•àª°à«‡àª•à«àª¶àª¨", "àªªà«‡àª°àª¿àªŸà«€", "àªšà«‡àª•àª¸àª®",
                    "àª¹à«‡àª®àª¿àª‚àª— àª•à«‹àª¡", "àª¸àª¾àª¯àª•à«àª²àª¿àª• àª°àª¿àª¡àª¨à«àª¡àª¨à«àª¸à«€ àªšà«‡àª•", "CRC", "àªàª°àª°àª¨àª¾ àª•àª¾àª°àª£à«‹", "àªàª°àª°àª¨à«€ àª…àª¸àª°",
                    
                    # àª²àª¾àª‡àª¨ àª•à«‹àª¡àª¿àª‚àª—
                    "àª²àª¾àª‡àª¨ àª•à«‹àª¡àª¿àª‚àª—", "àª²àª¾àª‡àª¨ àª•à«‹àª¡à«àª¸", "NRZ", "RZ", "àª®à«‡àª¨àªšà«‡àª¸à«àªŸàª°", "AMI",
                    "àª¯à«àª¨àª¿àªªà«‹àª²àª°", "àªªà«‹àª²àª°", "àª¬àª¾àª¯àªªà«‹àª²àª°", "àªµàª°à«àª—à«€àª•àª°àª£", "àªªà«àª°à«‹àªªàª°à«àªŸà«€àª",
                    "àªªàª¸àª‚àª¦àª—à«€", "àª¸àª°àª–àª¾àª®àª£à«€", "àªµà«‡àªµàª«à«‹àª°à«àª®"
                ]
            },
            
            "Unit-IV": {
                "english": [
                    # Data communication basics
                    "data communication", "characteristics", "components", "data transmission",
                    "transmission techniques", "transmission mode", "simplex", "half duplex", "full duplex",
                    
                    # Serial and parallel communication
                    "serial communication", "parallel communication", "synchronous", "asynchronous",
                    "serial data communication", "parallel data communication",
                    
                    # Data representation and standards
                    "data representation", "RS-232", "RS-422", "RS-485", "standards",
                    "communication ports", "USB", "HDMI", "RCA", "ethernet", "industrial standards",
                    
                    # Multimedia communication
                    "multimedia communication", "multimedia systems", "elements", "model",
                    "multimedia processing", "digital media", "signal processing",
                    "audio formats", "video formats", "image formats", "file formats",
                    
                    # Communication protocols and interfaces
                    "protocols", "interfaces", "pin diagram", "voltage levels", "connector",
                    "communication standards", "data formats"
                ],
                "gujarati": [
                    # àª¡à«‡àªŸàª¾ àª•à«‹àª®à«àª¯à«àª¨àª¿àª•à«‡àª¶àª¨ àª®à«‚àª³àª­à«‚àª¤à«‹
                    "àª¡à«‡àªŸàª¾ àª•à«‹àª®à«àª¯à«àª¨àª¿àª•à«‡àª¶Ù†", "àª²àª¾àª•à«àª·àª£àª¿àª•àª¤àª¾àª“", "àª˜àªŸàª•à«‹", "àª¡à«‡àªŸàª¾ àªŸà«àª°àª¾àª¨à«àª¸àª®àª¿àª¶àª¨",
                    "àªŸà«àª°àª¾àª¨à«àª¸àª®àª¿àª¶àª¨ àª¤àª•àª¨à«€àª•à«‹", "àªŸà«àª°àª¾àª¨à«àª¸àª®àª¿àª¶àª¨ àª®à«‹àª¡", "àª¸àª¿àª®à«àªªà«àª²à«‡àª•à«àª¸", "àª¹àª¾àª« àª¡à«àªªà«àª²à«‡àª•à«àª¸", "àª«à«àª² àª¡à«àªªà«àª²à«‡àª•à«àª¸",
                    
                    # àª¸à«€àª°àª¿àª¯àª² àª…àª¨à«‡ àªªà«‡àª°à«‡àª²àª² àª•à«‹àª®à«àª¯à«àª¨àª¿àª•à«‡àª¶àª¨
                    "àª¸à«€àª°àª¿àª¯àª² àª•à«‹àª®à«àª¯à«àª¨àª¿àª•à«‡àª¶àª¨", "àªªà«‡àª°à«‡àª²àª² àª•à«‹àª®à«àª¯à«àª¨àª¿àª•à«‡àª¶àª¨", "àª¸àª¿àª‚àª•à«àª°à«‹àª¨àª¸", "àª…àª¸àª¿àª‚àª•à«àª°à«‹àª¨àª¸",
                    "àª¸à«€àª°àª¿àª¯àª² àª¡à«‡àªŸàª¾ àª•à«‹àª®à«àª¯à«àª¨àª¿àª•à«‡àª¶àª¨", "àªªà«‡àª°à«‡àª²àª² àª¡à«‡àªŸàª¾ àª•à«‹àª®à«àª¯à«àª¨àª¿àª•à«‡àª¶àª¨",
                    
                    # àª¡à«‡àªŸàª¾ àª°à«‡àªªà«àª°à«‡àªàª¨à«àªŸà«‡àª¶àª¨ àª…àª¨à«‡ àª¸à«àªŸàª¾àª¨à«àª¡àª°à«àª¡à«àª¸
                    "àª¡à«‡àªŸàª¾ àª°à«‡àªªà«àª°à«‡àªàª¨à«àªŸà«‡àª¶àª¨", "RS-232", "RS-422", "RS-485", "àª¸à«àªŸàª¾àª¨à«àª¡àª°à«àª¡à«àª¸",
                    "àª•à«‹àª®à«àª¯à«àª¨àª¿àª•à«‡àª¶àª¨ àªªà«‹àª°à«àªŸà«àª¸", "USB", "HDMI", "RCA", "àª‡àª¥àª°àª¨à«‡àªŸ", "àª‡àª¨à«àª¡àª¸à«àªŸà«àª°àª¿àª¯àª² àª¸à«àªŸàª¾àª¨à«àª¡àª°à«àª¡à«àª¸",
                    
                    # àª®àª²à«àªŸàª¿àª®à«€àª¡àª¿àª¯àª¾ àª•à«‹àª®à«àª¯à«àª¨àª¿àª•à«‡àª¶àª¨
                    "àª®àª²à«àªŸàª¿àª®à«€àª¡àª¿àª¯àª¾ àª•à«‹àª®à«àª¯à«àª¨àª¿àª•à«‡àª¶àª¨", "àª®àª²à«àªŸàª¿àª®à«€àª¡àª¿àª¯àª¾ àª¸àª¿àª¸à«àªŸàª®à«àª¸", "àª¤àª¤à«àªµà«‹", "àª®à«‹àª¡à«‡àª²",
                    "àª®àª²à«àªŸàª¿àª®à«€àª¡àª¿àª¯àª¾ àªªà«àª°à«‹àª¸à«‡àª¸àª¿àª‚àª—", "àª¡àª¿àªœàª¿àªŸàª² àª®à«€àª¡àª¿àª¯àª¾", "àª¸àª¿àª—à«àª¨àª² àªªà«àª°à«‹àª¸à«‡àª¸àª¿àª‚àª—",
                    "àª“àª¡àª¿àª¯à«‹ àª«à«‹àª°à«àª®à«‡àªŸà«àª¸", "àªµàª¿àª¡àª¿àª¯à«‹ àª«à«‹àª°à«àª®à«‡àªŸà«àª¸", "àª‡àª®à«‡àªœ àª«à«‹àª°à«àª®à«‡àªŸà«àª¸", "àª«àª¾àª‡àª² àª«à«‹àª°à«àª®à«‡àªŸà«àª¸",
                    
                    # àª•à«‹àª®à«àª¯à«àª¨àª¿àª•à«‡àª¶àª¨ àªªà«àª°à«‹àªŸà«‹àª•à«‹àª²à«àª¸ àª…àª¨à«‡ àª‡àª¨à«àªŸàª°àª«à«‡àª¸àª¿àª¸
                    "àªªà«àª°à«‹àªŸà«‹àª•à«‹àª²à«àª¸", "àª‡àª¨à«àªŸàª°àª«à«‡àª¸àª¿àª¸", "àªªàª¿àª¨ àª¡àª¾àª¯àª¾àª—à«àª°àª¾àª®", "àªµà«‹àª²à«àªŸà«‡àªœ àª²à«‡àªµàª²à«àª¸", "àª•àª¨à«‡àª•à«àªŸàª°",
                    "àª•à«‹àª®à«àª¯à«àª¨àª¿àª•à«‡àª¶àª¨ àª¸à«àªŸàª¾àª¨à«àª¡àª°à«àª¡à«àª¸", "àª¡à«‡àªŸàª¾ àª«à«‹àª°à«àª®à«‡àªŸà«àª¸"
                ]
            },
            
            "Unit-V": {
                "english": [
                    # Satellite communication
                    "satellite communication", "block diagram", "transponder", "uplink", "downlink",
                    "earth station", "satellite", "frequency bands", "C-band", "Ku-band", "Ka-band",
                    
                    # 5G technology
                    "5G technology", "5G", "data communication", "features", "advantages",
                    "high speed", "low latency", "massive connectivity", "network slicing",
                    "beamforming", "millimeter waves", "enhanced mobile broadband",
                    
                    # Spread spectrum
                    "spread spectrum", "communication", "techniques", "direct sequence",
                    "frequency hopping", "DSSS", "FHSS", "code division multiple access",
                    "CDMA", "spreading", "despreading",
                    
                    # Edge computing and blockchain
                    "edge computing", "features", "distributed computing", "low latency",
                    "real-time processing", "blockchain", "communication security",
                    "decentralization", "immutability", "transparency", "cryptographic",
                    
                    # Privacy and ethical considerations
                    "privacy considerations", "ethical considerations", "data communication",
                    "security", "data protection", "encryption", "privacy rights"
                ],
                "gujarati": [
                    # àª¸à«‡àªŸà«‡àª²àª¾àª‡àªŸ àª•à«‹àª®à«àª¯à«àª¨àª¿àª•à«‡àª¶àª¨
                    "àª¸à«‡àªŸà«‡àª²àª¾àª‡àªŸ àª•à«‹àª®à«àª¯à«àª¨àª¿àª•à«‡àª¶àª¨", "àª¬à«àª²à«‹àª• àª¡àª¾àª¯àª¾àª—à«àª°àª¾àª®", "àªŸà«àª°àª¾àª¨à«àª¸àªªà«‹àª¨à«àª¡àª°", "àª…àªªàª²àª¿àª‚àª•", "àª¡àª¾àª‰àª¨àª²àª¿àª‚àª•",
                    "àª…àª°à«àª¥ àª¸à«àªŸà«‡àª¶àª¨", "àª¸à«‡àªŸà«‡àª²àª¾àª‡àªŸ", "àª«à«àª°à«€àª•à«àªµàª¨à«àª¸à«€ àª¬à«‡àª¨à«àª¡à«àª¸", "C-àª¬à«‡àª¨à«àª¡", "Ku-àª¬à«‡àª¨à«àª¡", "Ka-àª¬à«‡àª¨à«àª¡",
                    
                    # 5G àªŸà«‡àª•àª¨à«‹àª²à«‹àªœà«€
                    "5G àªŸà«‡àª•àª¨à«‹àª²à«‹àªœà«€", "5G", "àª¡à«‡àªŸàª¾ àª•à«‹àª®à«àª¯à«àª¨àª¿àª•à«‡àª¶àª¨", "àªµàª¿àª¶à«‡àª·àª¤àª¾àª“", "àª«àª¾àª¯àª¦àª¾àª“",
                    "àª¹àª¾àª‡ àª¸à«àªªà«€àª¡", "àª²à«‹ àª²à«‡àªŸàª¨à«àª¸à«€", "àª®à«‡àª¸àª¿àªµ àª•àª¨à«‡àª•à«àªŸàª¿àªµàª¿àªŸà«€", "àª¨à«‡àªŸàªµàª°à«àª• àª¸à«àª²àª¾àª‡àª¸àª¿àª‚àª—",
                    "àª¬à«€àª®àª«à«‹àª°à«àª®àª¿àª‚àª—", "àª®àª¿àª²àª¿àª®à«€àªŸàª° àªµà«‡àªµà«àª¸", "àªàª¨à«àª¹àª¾àª¨à«àª¸à«àª¡ àª®à«‹àª¬àª¾àª‡àª² àª¬à«àª°à«‹àª¡àª¬à«‡àª¨à«àª¡",
                    
                    # àª¸à«àªªà«àª°à«‡àª¡ àª¸à«àªªà«‡àª•à«àªŸà«àª°àª®
                    "àª¸à«àªªà«àª°à«‡àª¡ àª¸à«àªªà«‡àª•à«àªŸà«àª°àª®", "àª•à«‹àª®à«àª¯à«àª¨àª¿àª•à«‡àª¶àª¨", "àª¤àª•àª¨à«€àª•à«‹", "àª¡àª¾àª¯àª°à«‡àª•à«àªŸ àª¸àª¿àª•à«àªµàª¨à«àª¸",
                    "àª«à«àª°à«€àª•à«àªµàª¨à«àª¸à«€ àª¹à«‹àªªàª¿àª‚àª—", "DSSS", "FHSS", "àª•à«‹àª¡ àª¡àª¿àªµàª¿àªàª¨ àª®àª²à«àªŸàª¿àªªàª² àªàª•à«àª¸à«‡àª¸",
                    "CDMA", "àª¸à«àªªà«àª°à«‡àª¡àª¿àª‚àª—", "àª¡àª¿àª¸à«àªªà«àª°à«‡àª¡àª¿àª‚àª—",
                    
                    # àªàªœ àª•àª®à«àªªà«àª¯à«àªŸàª¿àª‚àª— àª…àª¨à«‡ àª¬à«àª²à«‹àª•àªšà«‡àª‡àª¨
                    "àªàªœ àª•àª®à«àªªà«àª¯à«àªŸàª¿àª‚àª—", "àªµàª¿àª¶à«‡àª·àª¤àª¾àª“", "àª¡àª¿àª¸à«àªŸà«àª°àª¿àª¬à«àª¯à«àªŸà«‡àª¡ àª•àª®à«àªªà«àª¯à«àªŸàª¿àª‚àª—", "àª²à«‹ àª²à«‡àªŸàª¨à«àª¸à«€",
                    "àª°àª¿àª¯àª²-àªŸàª¾àª‡àª® àªªà«àª°à«‹àª¸à«‡àª¸àª¿àª‚àª—", "àª¬à«àª²à«‹àª•àªšà«‡àª‡àª¨", "àª•à«‹àª®à«àª¯à«àª¨àª¿àª•à«‡àª¶àª¨ àª¸àª¿àª•à«àª¯à«àª°àª¿àªŸà«€",
                    "àª¡à«€àª¸à«‡àª¨à«àªŸà«àª°àª²àª¾àª‡àªà«‡àª¶àª¨", "àª‡àª®à«àª¯à«àªŸà«‡àª¬àª¿àª²àª¿àªŸà«€", "àªªàª¾àª°àª¦àª°à«àª¶àª¿àª¤àª¾", "àª•à«àª°àª¿àªªà«àªŸà«‹àª—à«àª°àª¾àª«àª¿àª•",
                    
                    # àª—à«‹àªªàª¨à«€àª¯àª¤àª¾ àª…àª¨à«‡ àª¨à«ˆàª¤àª¿àª• àªµàª¿àªšàª¾àª°àª£àª¾àª“
                    "àª—à«‹àªªàª¨à«€àª¯àª¤àª¾àª¨à«€ àªµàª¿àªšàª¾àª°àª£àª¾àª“", "àª¨à«ˆàª¤àª¿àª• àªµàª¿àªšàª¾àª°àª£àª¾àª“", "àª¡à«‡àªŸàª¾ àª•à«‹àª®à«àª¯à«àª¨àª¿àª•à«‡àª¶àª¨",
                    "àª¸àª¿àª•à«àª¯à«àª°àª¿àªŸà«€", "àª¡à«‡àªŸàª¾ àªªà«àª°à«‹àªŸà«‡àª•à«àª¶àª¨", "àªàª¨à«àª•à«àª°àª¿àªªà«àª¶àª¨", "àª—à«‹àªªàª¨à«€àª¯àª¤àª¾àª¨àª¾ àª…àª§àª¿àª•àª¾àª°à«‹"
                ]
            }
        }
        
        # Enhanced scoring weights for better accuracy
        self.scoring_weights = {
            'direct_match': 10.0,
            'partial_match': 5.0,
            'context_match': 3.0,
            'topic_match': 2.0,
            'length_bonus': 1.0,
            'technical_term_bonus': 2.0
        }
        
    def load_syllabus(self) -> Dict:
        """Load syllabus JSON file"""
        syllabus_file = self.base_path / "4343201.json"
        try:
            with open(syllabus_file, 'r', encoding='utf-8') as f:
                self.syllabus_data = json.load(f)
            print(f"âœ… Loaded syllabus from {syllabus_file}")
            return self.syllabus_data
        except Exception as e:
            print(f"âŒ Error loading syllabus: {e}")
            return {}
    
    def extract_questions_from_file(self, file_path: Path) -> List[Question]:
        """Extract questions from a solution file"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            questions = []
            
            # Determine language from filename
            language = 'gujarati' if '.gu.' in file_path.name else 'english'
            
            # Extract year and season from filename
            year_match = re.search(r'(\d{4})', file_path.name)
            season_match = re.search(r'(summer|winter)', file_path.name.lower())
            
            year = year_match.group(1) if year_match else 'unknown'
            season = season_match.group(1) if season_match else 'unknown'
            
            # Enhanced question extraction patterns for both languages
            if language == 'english':
                patterns = [
                    r'##\s+Question\s+(\d+)\([a-z]+\)\s+\[(\d+)\s+marks?\][\s\n]*\*\*(.+?)\*\*',
                    r'##\s+àªªà«àª°àª¶à«àª¨\s+(\d+)\([àª…-àª]+\)\s+\[(\d+)\s+àª—à«àª£\][\s\n]*\*\*(.+?)\*\*',
                    r'##\s+Q(?:uestion)?\s*(\d+)\.?([a-z]+)?\s*\[(\d+)\s*marks?\][\s\n]*(.+?)(?=##|$)',
                ]
            else:  # gujarati
                patterns = [
                    r'##\s+àªªà«àª°àª¶à«àª¨\s+(\d+)\([àª…-àª]+\)\s+\[(\d+)\s+àª—à«àª£\][\s\n]*\*\*(.+?)\*\*',
                    r'##\s+Question\s+(\d+)\([a-z]+\)\s+\[(\d+)\s+marks?\][\s\n]*\*\*(.+?)\*\*',
                ]
            
            for pattern in patterns:
                matches = re.finditer(pattern, content, re.MULTILINE | re.DOTALL | re.IGNORECASE)
                
                for match in matches:
                    try:
                        if len(match.groups()) == 3:
                            question_num, marks, text = match.groups()
                        elif len(match.groups()) == 4:
                            question_num, sub_part, marks, text = match.groups()
                            marks = sub_part if marks.isdigit() else marks
                        else:
                            continue
                        
                        # Clean question text
                        text = re.sub(r'\*\*', '', text)
                        text = re.sub(r'\n+', ' ', text)
                        text = text.strip()
                        
                        if len(text) < 10:  # Skip very short questions
                            continue
                        
                        # Create question ID
                        question_id = hashlib.md5(f"{file_path.name}_{question_num}_{text[:50]}".encode()).hexdigest()[:8]
                        
                        question = Question(
                            id=question_id,
                            text=text,
                            language=language,
                            marks=int(marks) if marks.isdigit() else 0,
                            source_file=file_path.name,
                            exam_year=year,
                            exam_season=season,
                            topics=[]
                        )
                        
                        questions.append(question)
                        
                    except Exception as e:
                        print(f"âš ï¸ Error parsing question match: {e}")
                        continue
            
            print(f"ğŸ“„ Extracted {len(questions)} questions from {file_path.name}")
            return questions
            
        except Exception as e:
            print(f"âŒ Error reading file {file_path}: {e}")
            return []
    
    def normalize_text(self, text: str) -> str:
        """Normalize text for better matching"""
        # Convert to lowercase
        text = text.lower()
        
        # Remove extra whitespace
        text = re.sub(r'\s+', ' ', text).strip()
        
        # Remove special characters but keep essential ones
        text = re.sub(r'[^\w\s\-\.\(\)\/]', ' ', text)
        
        # Normalize unicode characters
        text = unicodedata.normalize('NFKD', text)
        
        return text
    
    def calculate_question_unit_score(self, question: Question, unit: str) -> float:
        """Calculate enhanced score for question-unit mapping"""
        normalized_text = self.normalize_text(question.text)
        score = 0.0
        
        # Get keywords for this unit in the question's language
        unit_keywords = self.unit_keywords.get(unit, {}).get(question.language, [])
        
        if not unit_keywords:
            return 0.0
        
        # Direct keyword matching with enhanced scoring
        for keyword in unit_keywords:
            normalized_keyword = self.normalize_text(keyword)
            
            # Exact match (highest score)
            if normalized_keyword in normalized_text:
                score += self.scoring_weights['direct_match']
                
                # Bonus for technical terms
                if len(keyword) > 3:
                    score += self.scoring_weights['technical_term_bonus']
            
            # Partial word matching
            words_in_text = set(normalized_text.split())
            keyword_words = set(normalized_keyword.split())
            
            common_words = words_in_text.intersection(keyword_words)
            if common_words:
                score += len(common_words) * self.scoring_weights['partial_match']
        
        # Length bonus for comprehensive questions
        if len(question.text) > 100:
            score += self.scoring_weights['length_bonus']
        
        # Context matching based on common DDC terms
        context_indicators = {
            "Unit-I": ["system", "block", "communication", "channel", "multiplexing", "TDM", "FDM"],
            "Unit-II": ["modulation", "ASK", "FSK", "PSK", "QPSK", "QAM", "waveform", "constellation"],
            "Unit-III": ["information", "entropy", "coding", "huffman", "shannon", "error", "line code"],
            "Unit-IV": ["data", "transmission", "serial", "parallel", "RS-232", "multimedia", "ports"],
            "Unit-V": ["satellite", "5G", "spread", "edge", "blockchain", "privacy", "security"]
        }
        
        unit_indicators = context_indicators.get(unit, [])
        for indicator in unit_indicators:
            if indicator.lower() in normalized_text:
                score += self.scoring_weights['context_match']
        
        return score
    
    def map_question_to_unit(self, question: Question) -> Tuple[str, float]:
        """Map question to most appropriate unit with confidence score"""
        unit_scores = {}
        
        for unit in self.unit_keywords.keys():
            score = self.calculate_question_unit_score(question, unit)
            unit_scores[unit] = score
        
        if not unit_scores or max(unit_scores.values()) == 0:
            return "Unknown", 0.0
        
        best_unit = max(unit_scores, key=unit_scores.get)
        best_score = unit_scores[best_unit]
        
        # Calculate confidence as normalized score
        total_possible_score = len(self.unit_keywords.get(best_unit, {}).get(question.language, [])) * self.scoring_weights['direct_match']
        confidence = min(best_score / max(total_possible_score, 1), 1.0) if total_possible_score > 0 else 0.0
        
        return best_unit, confidence
    
    def process_all_questions(self):
        """Process all solution files and extract questions"""
        solution_files = list(self.base_path.glob("*solution*.md"))
        
        print(f"ğŸ” Found {len(solution_files)} solution files:")
        for file in solution_files:
            print(f"  ğŸ“ {file.name}")
        
        all_questions = []
        for file_path in solution_files:
            questions = self.extract_questions_from_file(file_path)
            all_questions.extend(questions)
        
        print(f"ğŸ“Š Total questions extracted: {len(all_questions)}")
        
        # Map questions to units
        mapped_questions = []
        mapping_stats = Counter()
        
        for question in all_questions:
            unit, confidence = self.map_question_to_unit(question)
            question.unit = unit
            question.confidence = confidence
            mapped_questions.append(question)
            mapping_stats[unit] += 1
        
        self.questions = mapped_questions
        
        print("\nğŸ“ˆ Unit mapping statistics:")
        for unit, count in mapping_stats.items():
            print(f"  {unit}: {count} questions")
        
        return mapped_questions
    
    def validate_mapping_accuracy(self) -> Dict:
        """Validate and report mapping accuracy"""
        stats = {
            'total_questions': len(self.questions),
            'mapped_questions': len([q for q in self.questions if q.unit != "Unknown"]),
            'high_confidence': len([q for q in self.questions if q.confidence > 0.7]),
            'medium_confidence': len([q for q in self.questions if 0.4 < q.confidence <= 0.7]),
            'low_confidence': len([q for q in self.questions if q.confidence <= 0.4]),
            'by_language': Counter([q.language for q in self.questions]),
            'by_unit': Counter([q.unit for q in self.questions]),
            'by_source': Counter([q.source_file for q in self.questions]),
            'unmapped_questions': [q for q in self.questions if q.unit == "Unknown"]
        }
        
        stats['mapping_accuracy'] = (stats['mapped_questions'] / stats['total_questions']) * 100 if stats['total_questions'] > 0 else 0
        stats['high_confidence_rate'] = (stats['high_confidence'] / stats['total_questions']) * 100 if stats['total_questions'] > 0 else 0
        
        return stats
    
    def generate_question_bank_json(self) -> Dict:
        """Generate final question bank JSON"""
        question_bank = {
            "metadata": {
                "course_code": "4343201",
                "course_title": "Digital and Data Communication",
                "semester": 4,
                "program": "Information and Communication Technology Engineering",
                "generated_at": "2024-12-19T10:00:00Z",
                "generator_version": "2.0",
                "total_questions": len(self.questions),
                "mapping_accuracy": f"{(len([q for q in self.questions if q.unit != 'Unknown']) / len(self.questions)) * 100:.2f}%" if self.questions else "0%"
            },
            "statistics": self.validate_mapping_accuracy(),
            "questions": []
        }
        
        # Group questions by unit
        for question in self.questions:
            question_data = asdict(question)
            question_bank["questions"].append(question_data)
        
        return question_bank
    
    def save_question_bank(self, output_file: str = "4343201-question-bank-final.json"):
        """Save question bank to JSON file"""
        question_bank = self.generate_question_bank_json()
        output_path = self.base_path / output_file
        
        try:
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(question_bank, f, indent=2, ensure_ascii=False)
            
            print(f"âœ… Question bank saved to {output_path}")
            return True
        except Exception as e:
            print(f"âŒ Error saving question bank: {e}")
            return False
    
    def run(self):
        """Run the complete question bank generation process"""
        print("ğŸš€ Starting Enhanced DDC Question Bank Generation...")
        print("=" * 60)
        
        # Step 1: Load syllabus
        print("\nğŸ“š Step 1: Loading syllabus...")
        self.load_syllabus()
        
        # Step 2: Process all questions
        print("\nğŸ”„ Step 2: Processing solution files...")
        self.process_all_questions()
        
        # Step 3: Validate mapping
        print("\nâœ… Step 3: Validating mapping accuracy...")
        stats = self.validate_mapping_accuracy()
        
        print(f"\nğŸ“Š Final Statistics:")
        print(f"  ğŸ“ Total questions: {stats['total_questions']}")
        print(f"  âœ… Successfully mapped: {stats['mapped_questions']} ({stats['mapping_accuracy']:.2f}%)")
        print(f"  ğŸ¯ High confidence: {stats['high_confidence']} ({stats['high_confidence_rate']:.2f}%)")
        print(f"  ğŸ“Š By language: {dict(stats['by_language'])}")
        print(f"  ğŸ“š By unit: {dict(stats['by_unit'])}")
        
        if stats['unmapped_questions']:
            print(f"\nâš ï¸  Unmapped questions ({len(stats['unmapped_questions'])}):")
            for q in stats['unmapped_questions']:
                print(f"    ğŸ”¸ {q.text[:60]}..." if len(q.text) > 60 else f"    ğŸ”¸ {q.text}")
        
        # Step 4: Save question bank
        print("\nğŸ’¾ Step 4: Saving question bank...")
        success = self.save_question_bank()
        
        if success:
            print(f"\nğŸ‰ Question bank generation completed successfully!")
            print(f"ğŸ“ˆ Achieved {stats['mapping_accuracy']:.2f}% mapping accuracy")
            print(f"ğŸ¯ {stats['high_confidence_rate']:.2f}% high-confidence mappings")
        else:
            print("\nâŒ Question bank generation failed!")
        
        print("=" * 60)


def main():
    """Main execution function"""
    base_path = "/Users/milav/Code/studio/content/resources/study-materials/32-ict/sem-4/4343201-ddc"
    
    generator = EnhancedDDCQuestionBankGenerator(base_path)
    generator.run()


if __name__ == "__main__":
    main()