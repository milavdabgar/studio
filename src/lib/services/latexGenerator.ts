import { marked, Token, Tokens } from 'marked';
import type { AnalysisResult } from '@/types/feedback';

export function generateNativeLatex(analysisResult: AnalysisResult): string {
    const { markdownReport, originalFileName, analysisDate } = analysisResult;

    // 1. Preamble
    const preamble = `\\documentclass[11pt,a4paper]{article}
\\usepackage[utf8]{inputenc}
\\usepackage{geometry}
\\geometry{a4paper, margin=1in}
\\usepackage{graphicx}
\\usepackage{booktabs}
\\usepackage{longtable}
\\usepackage{hyperref}
\\usepackage{xcolor}
\\usepackage{titlesec}
\\usepackage{fancyhdr}
\\usepackage{enumitem}
\\usepackage{float}

% Colors
\\definecolor{primary}{RGB}{0, 51, 102}
\\definecolor{secondary}{RGB}{0, 102, 204}

% Typography
\\usepackage{lmodern}
\\titleformat{\\section}{\\color{primary}\\Large\\bfseries}{\\thesection}{1em}{}
\\titleformat{\\subsection}{\\color{secondary}\\large\\bfseries}{\\thesubsection}{1em}{}

% Header/Footer
\\pagestyle{fancy}
\\fancyhf{}
\\rhead{\\small Feedback Analysis Report}
\\lhead{\\small ${escapeLatex(originalFileName)}}
\\cfoot{\\thepage}

\\title{\\textbf{\\Huge Feedback Analysis Report}\\\\ \\large ${escapeLatex(originalFileName)}}
\\author{Generated by GP Palanpur Feedback System}
\\date{Analyzed on: ${new Date(analysisDate).toLocaleDateString()}}

\\begin{document}

\\maketitle
\\tableofcontents
\\newpage

`;

    // 2. Body Generation (Parse Markdown)
    const tokens = marked.lexer(markdownReport);
    const body = parseTokens(tokens);

    // 3. Footer
    const footer = `
\\end{document}
`;

    return preamble + body + footer;
}

function parseTokens(tokens: Token[]): string {
    let latex = '';

    for (const token of tokens) {
        switch (token.type) {
            case 'heading': {
                const h = token as Tokens.Heading;
                const text = parseInline(h.text);
                if (h.depth === 1) latex += `\\section{${text}}\n`;
                else if (h.depth === 2) latex += `\\subsection{${text}}\n`;
                else if (h.depth === 3) latex += `\\subsubsection{${text}}\n`;
                else latex += `\\paragraph{${text}}\n`;
                break;
            }
            case 'paragraph': {
                const p = token as Tokens.Paragraph;
                // Skip paragraphs that are just images for now, or handle them
                latex += `${parseInline(p.text)}\n\n`;
                break;
            }
            case 'list': {
                const l = token as Tokens.List;
                const env = l.ordered ? 'enumerate' : 'itemize';
                latex += `\\begin{${env}}\n`;
                for (const item of l.items) {
                    latex += `  \\item ${parseTokens([item] as Token[]).trim()}\n`; // item.tokens usually exists but marked types are tricky
                }
                latex += `\\end{${env}}\n\n`;
                break;
            }
            case 'list_item': {
                const li = token as Tokens.ListItem;
                // List items can contain multiple block tokens
                // If it has tokens, use them, otherwise use text
                if (li.tokens && li.tokens.length > 0) {
                    latex += parseTokens(li.tokens);
                } else {
                    latex += parseInline(li.text);
                }
                break;
            }
            case 'table': {
                const t = token as Tokens.Table;
                latex += generateLatexTable(t);
                break;
            }
            case 'blockquote': {
                const b = token as Tokens.Blockquote;
                latex += `\\begin{quote}\n${parseTokens(b.tokens)}\n\\end{quote}\n\n`;
                break;
            }
            case 'space':
                latex += '\n';
                break;
            case 'hr':
                latex += '\\hrulefill\n\n';
                break;
            case 'text':
                const tx = token as Tokens.Text;
                // Handle text token. It can be a block level text token.
                if (tx.tokens) {
                    latex += parseTokens(tx.tokens);
                } else {
                    latex += parseInline(tx.text);
                }
                break;
            default:
                // Basic fallback for unknown tokens, strictly purely text
                // Many tokens might be handled by 'text' or 'html' case if not explicitly covered
                if ('text' in token) {
                    const t = token as { text: string };
                    latex += escapeLatex(t.text) + '\n';
                }
                break;
        }
    }

    return latex;
}

// Helper to parse inline formats (bold, italic, code)
// Since marked.lexer gives block tokens, inline text often contains **bold** etc.
// marked provides inlineLexer, but simpler regex replacement might be sufficient for "publishing quality" 
// if we don't want to re-run the full lexer for every string. 
// However, strictly, header text is NOT parsed by marked.lexer into inline tokens automatically in the 'text' property?
// Actually yes, it is just a string. 
// Let's implement a robust inline parser or simple replacements.
function parseInline(text: string): string {
    if (!text) return '';

    // Clean text
    let out = text;

    // Escape LaTeX special characters first
    // We must be careful not to escape syntax chars if we do replacements later?
    // Strategy: Escape EVERYTHING first, but then we can't process Markdown syntax.
    // Strategy: Process Markdown syntax, extracting content, escaping content, wrapping in LaTeX.

    // Basic Regex Replacements (Order matters)
    // 1. Code: `code`
    out = out.replace(/`([^`]+)`/g, (match, code) => `\\texttt{${escapeLatex(code)}}`);

    // 2. Bold: **bold** or __bold__
    out = out.replace(/(\*\*|__)(.*?)\1/g, (match, sep, content) => `\\textbf{${parseInline(content)}}`);

    // 3. Italic: *italic* or _italic_
    out = out.replace(/(\*|_)(.*?)\1/g, (match, sep, content) => `\\textit{${parseInline(content)}}`);

    // 4. Links: [text](url) -> \href{url}{text}
    out = out.replace(/\[([^\]]+)\]\(([^)]+)\)/g, (match, txt, url) => `\\href{${url}}{${parseInline(txt)}}`);

    // We need to escape special characters in the "text" parts, but ignoring the LaTeX commands we just inserted?
    // This regex approach is flawed because if I escape first, I break syntax tokens.
    // If I escape last, I escape the \textbf{...} I just added.

    // Better Approach: Use marked.parseInline() to get HTML, then HTML->LaTeX? No.
    // Best Approach: Simple character escaping for remaining text is okay IF we assume the LLM output is mostly clean.
    // But strictly, we should iterate character by character or use a proper tokenizer for inline too.
    // Given "Native LaTeX" requirement, let's just do a reasonably safe escape-then-regex, using unique placeholders?

    // Let's try to escape specific chars that are NOT part of markdown syntax first? No.
    // Let's rely on a simpler single-pass escape function that respects generic text.
    // Or, since we only need simple bold/italic/code/link:

    // We will assume "text" passed here needs escaping EXCEPT for the markdown markup.
    // Actually, marked has an `inlineLexer`. Let's use it if possible? 
    // `marked.lexer` parses blocks. `marked.parseInline` returns string/html.
    // `new marked.Lexer().inline(text)`?
    // Let's stick to a safe regex replacement that escapes "text content" only.

    // Actually, let's keep it simple: 
    // 1. Handle code blocks (protect them).
    // 2. Handle bold/italic.
    // 3. Escape the rest.

    // Simplified safe escape helper
    const simpleEscape = (str: string) => str
        .replace(/\\/g, '\\textbackslash{}')
        .replace(/([&%$#_{}])/g, '\\$1')
        .replace(/~/g, '\\textasciitilde{}')
        .replace(/\^/g, '\\textasciicircum{}');

    // We have to be careful. The input string contains `**bold**`.
    // If we escape first, we get `**bold**` (starts remain).
    // But if text is `foo & bar`, we get `foo \& bar`.
    // This seems safe to do FIRST, provided we don't accidentally escape the markdown chars `*`, `_`, `[`, `]`, `(`, `)`, `` ` ``.
    // Luckily `*`, `_`, `[`, `]`, `(`, `)` are NOT LaTeX special chars (except `_` and `[` sometimes).
    // `_` IS a special char. So `_italic_` becomes `\_italic\_`.

    // Correct Algorithm:
    // Split string by Markdown tokens (bold/italic/code/link), process them, escape the 'text' parts.

    // For this MVP, let's try a split/map approach on the most common inline patterns.
    // Supports: **bold**, *italic*, `code`.

    const tokens = [];
    let buffer = text;

    // Tokenizer pattern: Code OR Bold OR Italic OR Link OR Text
    const pattern = /(`[^`]+`)|(\*\*[^*]+\*\*)|(\*[^*]+\*)|(!?\[[^\]]*\]\([^)]+\))/g;

    let match;
    let lastIndex = 0;
    let result = "";

    while ((match = pattern.exec(text)) !== null) {
        // Text before match
        const before = text.slice(lastIndex, match.index);
        result += simpleEscape(before);

        const m = match[0];
        if (m.startsWith('`')) {
            // Code
            const content = m.slice(1, -1);
            result += `\\texttt{${simpleEscape(content)}}`; // latex-escape inside code? or verbatim? texttt needs escape.
        } else if (m.startsWith('**')) {
            // Bold
            const content = m.slice(2, -2);
            result += `\\textbf{${parseInline(content)}}`; // Recurse
        } else if (m.startsWith('*')) {
            // Italic
            const content = m.slice(1, -1);
            result += `\\textit{${parseInline(content)}}`; // Recurse
        } else if (m.startsWith('[')) {
            // Link [text](url)
            const linkMatch = m.match(/^\[(.*?)\]\((.*?)\)$/);
            if (linkMatch) {
                const txt = linkMatch[1];
                const url = linkMatch[2];
                result += `\\href{${url}}{${parseInline(txt)}}`;
            }
        } else {
            result += simpleEscape(m);
        }

        lastIndex = pattern.lastIndex;
    }

    // Remaining text
    result += simpleEscape(text.slice(lastIndex));
    return result;
}

function escapeLatex(text: string): string {
    if (!text) return '';
    return text
        .replace(/\\/g, '\\textbackslash{}')
        .replace(/([&%$#_{}])/g, '\\$1')
        .replace(/~/g, '\\textasciitilde{}')
        .replace(/\^/g, '\\textasciicircum{}');
}


function generateLatexTable(table: Tokens.Table): string {
    // Use longtable and booktabs for professional look
    const alignMap: Record<string, string> = {
        'left': 'l',
        'right': 'r',
        'center': 'c'
    };

    const colSpec = table.align.map((a: string | null) => alignMap[a || 'left']).join(' ');

    let latex = `
\\begin{longtable}{${colSpec}}
\\toprule
`;

    // Header
    latex += table.header.map((cell: Tokens.TableCell) => `\\textbf{${parseInline(cell.text)}}`).join(' & ') + ' \\\\\n';
    latex += '\\midrule\n';
    latex += '\\endhead\n'; // Longtable header repeat

    // Body
    for (const row of table.rows) {
        latex += row.map((cell: Tokens.TableCell) => parseInline(cell.text)).join(' & ') + ' \\\\\n';
    }

    latex += `\\bottomrule
\\end{longtable}
`;
    return latex;
}
